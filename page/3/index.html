<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport" />
    <meta content="yes" name="apple-mobile-web-app-capable" />
    <meta content="black-translucent" name="apple-mobile-web-app-status-bar-style" />
    <meta content="telephone=no" name="format-detection" />
    <title>
    叶某人的碎碎念 | Believe in Mathematics    </title>
    <link rel="stylesheet" type="text/css" href="/theme/css/style.css" />
    <link rel="stylesheet" type="text/css" href="/theme/css/pygment.css" />
    <link rel="stylesheet" type="text/css" href="/theme/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css" />
    <link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css" />
    <link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css" />
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
    <link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico" />
</head>

<body>
<div class="body_container">
    <div id="header">
        <div class="site-name">
            <a id="logo" href="/."> 叶某人的碎碎念 </a>
            <p class="description"> Believe in Mathematics </p>
        </div>
        <div id="nav-menu">
            <a href="/."><i class="fa fa-home"> Home</i></a>
            <a href="/movies/"><i class="fa fa-film"> Movies</i></a>
            <a href="/archives.html"><i class="fa fa-archive"> Archive</i></a>
        </div>
    </div>
    <div id="layout" class="pure-g">
        <div class="pure-u-1 pure-u-lg-3-4"><div class="content_container">
<div class="post">
    <h1 class="post-title"><a href="/20180325-markov-decision-process-finite-horizon/">Markov Decision Process: Finite horizon</a></h1>
    <div class="post-meta">2018-03-25</div>
    <a data-disqus-identifier="20180325-markov-decision-process-finite-horizon/" href="/20180325-markov-decision-process-finite-horizon/#disqus_thread" class="disqus-comment-count"></a>
    <div class="post-content">
        <p>This post is considered to the notes on finite horizon Markov decision process for lecture 18 in Andrew Ng's <a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599">lecture series</a>. In my previous two notes (<a href="https://wormtooth.com/20180207-markov-decision-process/">[1]</a>, <a href="https://wormtooth.com/20180306-markov-decision-process-continuous-states/">[2]</a>) about Markov decision process (MDP), only state rewards are considered. We can easily generalize MDP to state-action reward.</p>
<h2>State-Action Reward</h2>
<p>Our reward function now is a function in terms of both states and actions. More precisely, the reward function is a function<br>
</p>
<div class="math">$$R: S \times A \to \R.$$</div>
<p><br>
All other requirements in definition of MDP will remain intact. For completeness, we include the definition here. We shall pay attention to the fifth components.</p>

    </div>
    <p class="readmore"><a href="/20180325-markov-decision-process-finite-horizon/">Read More</a></p>
</div>
<div class="post">
    <h1 class="post-title"><a href="/20180306-markov-decision-process-continuous-states/">Markov Decision Process: Continuous states</a></h1>
    <div class="post-meta">2018-03-06</div>
    <a data-disqus-identifier="20180306-markov-decision-process-continuous-states/" href="/20180306-markov-decision-process-continuous-states/#disqus_thread" class="disqus-comment-count"></a>
    <div class="post-content">
        <p>I wrote this post for lecture 17 in Andrew Ng's lecture collections on <a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599">Machine Learning</a>. In my <a href="https://wormtooth.com/20180207-markov-decision-process/">previous post</a>, we discussed Markov Decision Process (MDP) in its simplest form, where the set of states and the set of actions are both finite. But in real world application, states and actions can be infinite and even continuous. For example, if we want to model states of a self-driving car in a 2D plane, we must at least have the position <span class="math">\((x, y)\)</span>, the direction <span class="math">\(\theta\)</span> of the car pointing to, its velocity <span class="math">\((v_x, v_y)\)</span> and the rate <span class="math">\(r\)</span> of change in <span class="math">\(\theta\)</span>. So the states of a car is at least a 6 dimensional space. For actions of a car, we can control how fast it goes in direction <span class="math">\(\theta\)</span> and we can also control <span class="math">\(r\)</span>. Thus the actions have dimension 2.</p>
<p>In this post, we consider only continuous states with finite actions. Indeed, actions space usually has much lower dimension than states space, so in case of continuous actions, we might just discretize the actions spaces to get a finite set of representatives of actions. One may argue that we can also discretize the states space. Yes, we can do it, but only when the dimension <span class="math">\(n\)</span> of state space is small enough: if we discretize each dimension into <span class="math">\(k\)</span> parts, then there would be <span class="math">\(k^n\)</span> many states. If <span class="math">\(n\)</span> is large, then <span class="math">\(k^n\)</span> is not feasible. This is so called the curse of dimensionality. Moreover, discretizing states space usually results in lack of smoothness.</p>

    </div>
    <p class="readmore"><a href="/20180306-markov-decision-process-continuous-states/">Read More</a></p>
</div>
<div class="post">
    <h1 class="post-title"><a href="/20180207-markov-decision-process/">Markov Decision Process</a></h1>
    <div class="post-meta">2018-02-07</div>
    <a data-disqus-identifier="20180207-markov-decision-process/" href="/20180207-markov-decision-process/#disqus_thread" class="disqus-comment-count"></a>
    <div class="post-content">
        <p>This article is my notes for 16th lecture in <a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599">Machine Learning</a> by Andrew Ng on Markov Decision Process (MDP). MDP is a typical way in machine learning to formulate <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>, whose tasks roughly speaking are to train agents to take actions in order to get maximal rewards in some settings. One example of reinforcement learning would be developing a game bot to play <a href="https://en.wikipedia.org/wiki/Super_Mario">Super Mario</a> on its own. </p>
<p>Another simple example is used in the lecture, and I will use it throughout the post as well. Since the example is really simple, so MDP shown below is not of the most general form, but only good enough to solve the example and give the idea of what MDP and reinforcement learning are. The example begins with a 3 by 4 grid as below.</p>
<p><img alt="the grid" src="/images/20180207-example-1.png"></p>

    </div>
    <p class="readmore"><a href="/20180207-markov-decision-process/">Read More</a></p>
</div>
<div class="post">
    <h1 class="post-title"><a href="/20180117-the-phantom-of-the-opera/">The Phantom of the Opera</a></h1>
    <div class="post-meta">2018-01-17</div>
    <a data-disqus-identifier="20180117-the-phantom-of-the-opera/" href="/20180117-the-phantom-of-the-opera/#disqus_thread" class="disqus-comment-count"></a>
    <div class="post-content">
        <p>周末晚（14号）我终于去看了久闻的歌剧魅影，果然十分震撼。</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/jUTQarYXSSo?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>


    </div>
    <p class="readmore"><a href="/20180117-the-phantom-of-the-opera/">Read More</a></p>
</div>
<div class="post">
    <h1 class="post-title"><a href="/20180113-principal-component-analysis/">Principal Component Analysis</a></h1>
    <div class="post-meta">2018-01-13</div>
    <a data-disqus-identifier="20180113-principal-component-analysis/" href="/20180113-principal-component-analysis/#disqus_thread" class="disqus-comment-count"></a>
    <div class="post-content">
        <p>This article is my notes on Principal Component Analysis (PCA) for Lecture 14 and 15 of <a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599">Machine Learning</a> by Andrew Ng. Given a set of high dimensional data <span class="math">\(\{x^{(1)}, \dots, x^{(m)}\}\)</span>, where each <span class="math">\(x^{(i)} \in \R^{n}\)</span>, with the assumption that these data actually roughly lie in a much smaller <span class="math">\(k\)</span> dimensional subspace, PCA tries to find a basis for this <span class="math">\(k\)</span> dimensional subspace. Let's look at a simple example:</p>
<pre><matplotlib.figure.Figure at 0x10a0c6d68></pre>

<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/></p>

    </div>
    <p class="readmore"><a href="/20180113-principal-component-analysis/">Read More</a></p>
</div>
<div class="post">
    <h1 class="post-title"><a href="/20180106-pork-chop/">烤猪排</a></h1>
    <div class="post-meta">2018-01-06</div>
    <a data-disqus-identifier="20180106-pork-chop/" href="/20180106-pork-chop/#disqus_thread" class="disqus-comment-count"></a>
    <div class="post-content">
        <p>来到路村的第一件事是长胖。某人的厨艺实在了得，此次记录的是她的代表作之一——烤猪排。</p>
<p><img alt="烤猪排" src="/images/20180106-pork-chop-finish.jpeg" style="width: 350px;" /></p>

    </div>
    <p class="readmore"><a href="/20180106-pork-chop/">Read More</a></p>
</div>
<div class="post">
    <h1 class="post-title"><a href="/20171125-leetcode-contest-60/">LeetCode Contest 60</a></h1>
    <div class="post-meta">2017-11-25</div>
    <a data-disqus-identifier="20171125-leetcode-contest-60/" href="/20171125-leetcode-contest-60/#disqus_thread" class="disqus-comment-count"></a>
    <div class="post-content">
        <p>这次<a href="https://leetcode.com/contest/weekly-contest-60">比赛</a>不难，但是我在最简单的两题各错了一次。</p>
<p><a href="https://leetcode.com/contest/weekly-contest-60/problems/flood-fill/">第一题</a><code>Flood Fill</code></p>
<div class="qbar">
<p>给定一个二维数组表示一张图片，以及一个坐标<code>(r, c)</code>。我们需要包含这个坐标且数字一样的连通分支整体变成另一个数。</p>
</div>
<p>我记得高中的时候学到Flood Fill这个词的时候有种莫名开心，可能是因为这个名字很形象地描述了DFS的过程吧。</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Solution</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">floodFill</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">sr</span><span class="p">,</span> <span class="n">sc</span><span class="p">,</span> <span class="n">newColor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :type image: List[List[int]]</span>
<span class="sd">        :type sr: int</span>
<span class="sd">        :type sc: int</span>
<span class="sd">        :type newColor: int</span>
<span class="sd">        :rtype: List[List[int]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">visited</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">color</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="n">sr</span><span class="p">][</span><span class="n">sc</span><span class="p">]</span>

        <span class="k">def</span> <span class="nf">dfs</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
            <span class="n">image</span><span class="p">[</span><span class="n">r</span><span class="p">][</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">newColor</span>
            <span class="n">visited</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">dr</span><span class="p">,</span> <span class="n">dc</span> <span class="ow">in</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]:</span>
                <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">r</span><span class="o">+</span><span class="n">dr</span><span class="p">,</span> <span class="n">c</span><span class="o">+</span><span class="n">dc</span>
                <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">y</span> <span class="o">&gt;=</span> <span class="n">m</span> <span class="ow">or</span> <span class="n">image</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span> <span class="o">!=</span> <span class="n">color</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="n">dfs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="n">dfs</span><span class="p">(</span><span class="n">sr</span><span class="p">,</span> <span class="n">sc</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image</span>
</pre></div>



    </div>
    <p class="readmore"><a href="/20171125-leetcode-contest-60/">Read More</a></p>
</div>
<div class="post">
    <h1 class="post-title"><a href="/20171112-egg-noodle/">蒜蓉鸡蛋面</a></h1>
    <div class="post-meta">2017-11-12</div>
    <a data-disqus-identifier="20171112-egg-noodle/" href="/20171112-egg-noodle/#disqus_thread" class="disqus-comment-count"></a>
    <div class="post-content">
        <p>最近学会了手工鸡蛋面，然后就开始各种黑暗尝试。我第一次的黑暗尝试是在面中加葱，所以揉出来的面是绿色的。</p>
<p><img alt="葱蛋面" src="/images/20171112-onion-noodle.jpg"></p>

    </div>
    <p class="readmore"><a href="/20171112-egg-noodle/">Read More</a></p>
</div>
<div class="post">
    <h1 class="post-title"><a href="/20171109-factor-analysis/">Factor Analysis</a></h1>
    <div class="post-meta">2017-11-09</div>
    <a data-disqus-identifier="20171109-factor-analysis/" href="/20171109-factor-analysis/#disqus_thread" class="disqus-comment-count"></a>
    <div class="post-content">
        <p>This article is my notes on the topic of factor analysis. These notes come out of lecture 13 and 14 of Andrew Ng's <a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599">online course</a>. Roughly speaking, factor analysis models some <span class="math">\(n\)</span> dimensional observed data with the assumption that these data are actually from some <span class="math">\(d\)</span> dimensional plane in <span class="math">\(\R\)</span>, up to some Gaussian distributed errors. Let's make it more precise.</p>
<p>Suppose we have a set of observed data <span class="math">\(\{x^{(1)}, \dots, x^{(m)}\}\)</span> implicitly labeled by some latent random variable <span class="math">\(z \in \R^d\)</span> where<br>
</p>
<div class="math">$$z \sim \mathcal{N}(0, I).$$</div>
<p> <br>
Factor analysis model tries to model <span class="math">\(P(x)\)</span> using the assumption that<br>
</p>
<div class="math">$$\begin{equation}
x|z \sim \mathcal{N}(\mu+\Lambda z, \Psi),
\label{cond-xz}
\end{equation}$$</div>
<p><br>
for some <span class="math">\(\mu \in \R^n, \Lambda \in \R^{n \times d}\)</span> and <strong>diagonal matrix</strong> <span class="math">\(\Psi \in \R^{n \times n}\)</span>. These <span class="math">\(\mu, \Lambda\)</span> and <span class="math">\(\Psi\)</span> are parameters of the model.</p>

    </div>
    <p class="readmore"><a href="/20171109-factor-analysis/">Read More</a></p>
</div>
<div class="post">
    <h1 class="post-title"><a href="/20171105-expectation-maximization/">Expectation-Maximization algorithm</a></h1>
    <div class="post-meta">2017-11-05</div>
    <a data-disqus-identifier="20171105-expectation-maximization/" href="/20171105-expectation-maximization/#disqus_thread" class="disqus-comment-count"></a>
    <div class="post-content">
        <p>In this article, I will collect my notes on Expectation-Maximization algorithm (EM) based on lecture 12 and 13 of Andrew Ng's <a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599">online course</a>. Given a set of unlabeled data points EM tries iteratively to determine the distribution of data, assuming that all data points are implicitly labeled (unobserved latent variables). For simplicity, we shall limit ourselves to the case where there are only finitely many implicit labels.</p>
<h2>Description of the problem</h2>
<p>Given a set of unlabeled data <span class="math">\(\{x^{(1)}, \dots, x^{(m)}\}\)</span>, our goal is to determine <span class="math">\(P(x)\)</span>, the distribution of <span class="math">\(x\)</span>, with the following assumptions.</p>
<div class="qbar">
<p><a name="assumptions"><strong>Assumptions.</strong></a></p>
<ol>
<li>
<p>There are finitely many unobserved latent variables <span class="math">\(z \in \{1, \dots, k\}\)</span> and they obey some multinomial distribution, i.e., <span class="math">\(P(z=j) = \phi_j\)</span> with <span class="math">\(\sum \phi_j = 1\)</span>.</p>
</li>
<li>
<p><span class="math">\(\{P(x|z=j; a_j): j=1, \dots, k\}\)</span> are a family of uniformly parametrized distribution.</p>
</li>
</ol>
</div>
<p>Assumptions 1 and 2 will gives us a set of parameters <span class="math">\(\theta = (\phi_1, \dots, \phi_j, a_1,\dots, a_j)\)</span> and<br>
</p>
<div class="math">$$\begin{equation}
P(x; \theta) = \sum_{j=1}^k P(x|z=j; \theta)P(z=j; \theta).
\label{px}
\end{equation}$$</div>
<p><br>
We want to find this set of parameters so that the likelihood function<br>
</p>
<div class="math">$$L(\theta) = \prod_{i=1}^m P(x^{(i)}) = \prod_{i=1}^m \sum_{j=1}^k P(x^{(i)}|z=j; \theta)P(z=j; \theta).$$</div>
<p><br>
is maximized. Or equivalently, the log likelihood function below is maximized:<br>
</p>
<div class="math">$$\begin{equation}
l(\theta) = \sum_{i=1}^m \log\left(\sum_{j=1}^k P(x^{(i)}, z=j; \theta)\right),
\label{log-likelihood}
\end{equation}$$</div>
<p><br>
where <br>
</p>
<div class="math">$$P(x^{(i)}, z=j; \theta) = P(x^{(i)}|z=j; \theta)P(z=j; \theta).$$</div>

    </div>
    <p class="readmore"><a href="/20171105-expectation-maximization/">Read More</a></p>
</div>

<div class="page-navigator">
    <a class="extend prev" rel="prev" href="/page/2/">Previous</a>
    <a class="page-number" href="/">1</a>
    <a class="page-number" href="/page/2/">2</a>
    <span class="page-number current">3</span>
    <a class="page-number" href="/page/4/">4</a>
    <a class="page-number" href="/page/5/">5</a>
    <span class="space">...</span>
    <a class="page-number" href="/page/10/">10</a>
    <a class="extend next" rel="next" href="/page/4/">Next</a></nav>
</div class="page-navigator">

    <script id="dsq-count-scr" src="//wormtooth.disqus.com/count.js" async></script>

        </div></div>
        <div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar">
<div class="widget">
    <form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form">
        <input type="text" name="q" maxlength="20" placeholder="Search"/>
        <input type="hidden" name="sitesearch" value="https://wormtooth.com"/>
    </form>
</div><div class="widget">
    <div class="widget-title"><i class="fa fa-heart-o"> 年轻的心只有一面</i></div>
    <img src="/images/mobius_heart.png" class="nofancybox" />
</div><div class="widget">
    <div class="widget-title"><i class="fa fa-paper-plane-o"> 心情随笔</i></div>
    <p>含蓄的极致是闷骚，闷骚的极致是深情。</p>
    <span class="qed"><a href="/scribble">View All</a></span>
</div><div class="widget">
    <div class="widget-title">
        <i class="fa fa-folder-o"> Categories</i>
    </div>
    <ul class="category-list">
        <li class="category-list-item"><a class="category-list-link" href="/category/life/">Life</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/machine-learning/">Machine Learning</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/mathematics/">Mathematics</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/notes/">Notes</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/programming/">Programming</a></li>
    </ul>
</div><div class="widget">
    <div class="widget-title"><i class="fa fa-external-link"> Blogroll</i></div>
    <ul></ul>
    <a href="https://yongjiasong.com/" title="JOY DOMAIN" target="_blank">JOY DOMAIN</a>
</div>
<div class="widget">
    <div class="widget-title"><i class="fa fa-comment-o"> Recent Comments</i></div>
    <script type="text/javascript" src="//wormtooth.disqus.com/recent_comments_widget.js?num_items=5&hide_avatars=1&avatar_size=32&excerpt_length=20&hide_mods=1"></script>
</div>
        </div></div>
        <div class="pure-u-1 pure-u-lg-3-4">
<div id="footer">Copyright © 2020 <a href="/." rel="nofollow">叶某人的碎碎念.</a> <a rel="nofollow" target="_blank" href="https://getpelican.com/">Pelican</a> &amp; <a rel="nofollow", target="_blank", href="https://github.com/wormtooth/maupassant-pelican">maupassant</a>.</div>        </div>
    </div>
</div>
<a id="rocket" href="#top" class="show"></a>
<script type="text/javascript" src="/theme/js/totop.js" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.js" async></script>
<script type="text/javascript" src="/theme/js/fancybox.js" async></script>
<link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.css" />

<script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      },
      Macros: {
        N: "\\mathbb{N}",
        Z: "\\mathbb{Z}",
        Q: "\\mathbb{Q}",
        R: "\\mathbb{R}",
        C: "\\mathbb{C}"
      }
    },
    'HTML-CSS': {
      imageFont: null
    }
  });
</script>
<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.1.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>