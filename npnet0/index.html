<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport" />
    <meta content="yes" name="apple-mobile-web-app-capable" />
    <meta content="black-translucent" name="apple-mobile-web-app-status-bar-style" />
    <meta content="telephone=no" name="format-detection" />
    <title>
[npnet] 序言 | 叶某人的碎碎念    </title>
    <link rel="stylesheet" type="text/css" href="/theme/css/style.css" />
    <link rel="stylesheet" type="text/css" href="/theme/css/pygment.css" />
    <link rel="stylesheet" type="text/css" href="/theme/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css" />
    <link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css" />
    <link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css" />
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
    <link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico" />
</head>

<body>
<div class="body_container">
    <div id="header">
        <div class="site-name">
            <a id="logo" href="/."> 叶某人的碎碎念 </a>
            <p class="description"> Believe in Mathematics </p>
        </div>
        <div id="nav-menu">
            <a href="/."><i class="fa fa-home"> Home</i></a>
            <a href="/movies/"><i class="fa fa-film"> Movies</i></a>
            <a href="/archives.html"><i class="fa fa-archive"> Archive</i></a>
        </div>
    </div>
    <div id="layout" class="pure-g">
        <div class="pure-u-1 pure-u-lg-3-4"><div class="content_container">
<div class="post">
    <h1 class="post-title">[npnet] 序言</h1>
    <div class="post-meta">Sep 25, 2019
    <span> | </span> <span>Machine Learning</span>
    </div>
    <a data-disqus-identifier="npnet0/" href="/npnet0/#disqus_thread" class="disqus-comment-count"></a>
    <div class="post-content">
        <p>很早之前我就有一个“写一个机器学习的系列笔记”的想法了。之所以叫做“笔记”而不叫“教程”，是因为机器学习只是我的业余爱好之一，我并不精通此道。事实上，我只是学到最简单的皮毛知识，还不一定明白透彻。所以我把我将要写的这个系列定义为笔记，并且在开篇就写得明明白白，这样我就可以随心所欲地写而并不担心误人子弟。不过既然我把笔记放在网上了，那表明我也希望其他人能从我写的东西里得到启发。如果你发现我的理解有误或者文章有错，也请务必留言让我知道。</p>
<!--more-->

<p>这个系列的名字叫做 <strong>npnet</strong>，意思是要用 <a href="https://numpy.org">numpy</a> 去实现一些机器学习的算法。暂定的目标是实现线性模型，CNN， RNN 以及这些基本模型的简单复合（类似 <a href="https://pytorch.org/docs/stable/nn.html#sequential">torch.nn.Sequential</a>）。这些算法实现只是为了学习算法背后的理论，并不是为了用于实践。如果你希望在实际应用中使用机器学习，那么你应该去学习现有的库，比如 <a href="https://pytorch.org">PyTorch</a> 和 <a href="https://www.tensorflow.org">TensorFlow</a>。我是参考 PyTorch 来设计这些算法的。</p>
<p>此系列的算法实现环境是 Python 3.7.3，numpy 的版本是 1.17.2。</p>
<div class="highlight"><pre><span></span><span class="c1"># import</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">py</span> <span class="o">=</span> <span class="s1">&#39;Python &#39;</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="p">[:</span><span class="mi">3</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Jupyter notebook with kernel: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">py</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Numpy version: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>
</pre></div>


<pre>Jupyter notebook with kernel: Python 3.7.3
Numpy version: 1.17.2
</pre>

<h1>机器学习算法的三个模块</h1>
<p>接下来我们用一个简单的例子——线性回归 (linear regression)——来看一下机器学习算法的主要组成部分。</p>
<div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">x</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">z</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img src="data:image/png;base64,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
"/></p>
<p>上图中蓝色直线代表的是一个我们想知道的“真理”。虽然这个“真理”是一条直线，但是由于技术的限制或者人为因素，现实中我们只能观测到一些差不多在一条直线上的红色的点。线性回归的目标是从这些观测点推测出最合理的直线。将这个问题进一步抽象成一个数学问题：给定一些点<br>
</p>
<div class="math">$$\{(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)\},$$</div>
<p><br>
我们要找到一条最为拟合的直线<br>
</p>
<div class="math">$$y = ax + b.$$</div>
<p><br>
上述的抽象包含了机器学习的一个重要概念，<strong>模型 (model)</strong>。我们需要找的直线就是这个问题中的模型。模型中最为重要的东西就是模型的<em>参数 (parameters)</em>。比如直线由两个参数 <span class="math">\(a\)</span> 和 <span class="math">\(b\)</span> 确定，要找最合适的直线其实等价于寻找最为合适的参数<span class="math">\(a\)</span> 和 <span class="math">\(b\)</span>。</p>
<p>如何确定模型的参数呢？在我们的例子中，我们如何根据给定的点来找到 <span class="math">\(a\)</span> 和 <span class="math">\(b\)</span> 呢？在回答这个问题之前，我们还必须需要选择一个<strong>标准 (criterion)</strong> 来判断参数 <span class="math">\(a\)</span> 和 <span class="math">\(b\)</span> 的优劣。这是机器学习中第二个重要的概念。以我们的线性回归为例，对于某个观测点 <span class="math">\((x_i, y_i)\)</span>，模型给出的值是 <span class="math">\(\tilde{y}_i = ax_i + b\)</span>。我们希望 <span class="math">\(\tilde{y}_i\)</span> 越接近 <span class="math">\(y_i\)</span> 越好，换句话说我们希望两者差的绝对值 <span class="math">\(|\tilde{y}_i - y_i|\)</span> 越小越好。我们希望所有观测点都能接近模型给出的预测值，因此我们取所有的观测值与预测值之间差的绝对值的平均值来给出一个标准来判断 <span class="math">\(a\)</span> 和 <span class="math">\(b\)</span> 的好坏：<br>
</p>
<div class="math">$$L_1(a, b) = \frac{1}{n} \sum_{i = 1}^n |\tilde{y}_i - y_i| = \frac{1}{n} \sum_{i = 1}^n |ax_i +b - y_i|.$$</div>
<p><br>
<span class="math">\(L_1(a, b)\)</span> 的值越小表示 <span class="math">\(a\)</span> 和 <span class="math">\(b\)</span> 越好。我们希望找到 <span class="math">\(a\)</span> 和 <span class="math">\(b\)</span> 使得 <span class="math">\(L_1(a, b)\)</span> 的值达到最小。</p>
<p>正像参数 <span class="math">\(a\)</span> 和 <span class="math">\(b\)</span> 有优劣之分，标准也有好坏之分。在微积分里我们学过使用导数去求函数的最值。<span class="math">\(L_1(a, b)\)</span> 是一个判断的标准，但是其中包含的绝对值函数 (<span class="math">\(y = |x|\)</span>) 在 <span class="math">\(x = 0\)</span> 处并不可导，所以我们不能简单地使用微积分的知识去找它的最小值。这种情况下，我们不认为 <span class="math">\(L_1\)</span> 是一个好的标准。我们知道 <span class="math">\(|\tilde{y}_i - y_i|\)</span>小 等价于 <span class="math">\(\frac{1}{2}(\tilde{y}_i - y_i)^2\)</span>小，而 <span class="math">\(y = \frac{1}{2}x^2\)</span> 是一个处处可导的函数，因此我们有一个更好的标准：<br>
</p>
<div class="math">$$L_2(a, b) = \frac{1}{2n} \sum_{i = 1}^n (\tilde{y}_i - y_i)^2 = \frac{1}{2n} \sum_{i = 1}^n (ax_i +b - y_i)^2.$$</div>
<p><br>
<span class="math">\(L_2\)</span> 是机器学习中常用的标准，它的名字为均方误差 (mean square error)。公式中出现的 <span class="math">\(\frac{1}{2}\)</span> 只是为了方便：<span class="math">\(y = \frac{1}{2}x^2\)</span> 的导数是 <span class="math">\(y = x\)</span>。从这两个标准我们可以大概看出一些门道来。在寻找标准的时候我们一般是先衡量一个观测点与预测值的局部错误，而后取所有局部错误的平均值作为一个衡量模型（或者参数）的标准。这些衡量模型好坏的标准也常被称为<em>损失函数 (loss function)</em>。</p>
<p>现在我们可以根据设定的标准来找到最好的模型了。这个过程是在<strong>优化 (optimize)</strong> 使得标准给出的错误值最小。优化是机器学习中第三个最重要的组成部分。这个组成部分也经常被称作<em>学习 (learning)</em>， 或者<em>训练 (training)</em>。我们可以使用微积分的方法来优化 <span class="math">\(L_2(a, b)\)</span>。<br>
</p>
<div class="math">$$\begin{align*}
    &amp;\frac{\partial L_2}{\partial a} = \frac{1}{n} \sum_{i = 1}^n (ax_i+b-y_i)x_i = 0, \\
    &amp;\frac{\partial L_2}{\partial b} = \frac{1}{n} \sum_{i = 1}^n (ax_i+b-y_i) = 0.
\end{align*}$$</div>
<p><br>
由此我们解出<br>
</p>
<div class="math">$$\begin{align*}
    &amp;a = \frac{\left(\sum_{i=1}^n x_i\right)\left(\sum_{i=1}^n y_i\right) - n\left(\sum_{i=1}^n x_iy_i\right)}{\left(\sum_{i=1}^n x_i\right)^2 - n \left(\sum_{i=1}^n x_i^2\right)},\\
    &amp;b = \frac{\left(\sum_{i=1}^n x_i\right)\left(\sum_{i=1}^n x_iy_i\right) - \left(\sum_{i=1}^n y_i\right)\left(\sum_{i=1}^n x_i^2\right)}{\left(\sum_{i=1}^n x_i\right)^2 - n \left(\sum_{i=1}^n x_i^2\right)}.
\end{align*}$$</div>
<p>我们使用上述公式求出 <span class="math">\(a\)</span> 和 <span class="math">\(b\)</span> 的值：</p>
<div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">sx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">sy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">sxy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span>
<span class="n">sx2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">a</span> <span class="o">=</span> <span class="p">(</span><span class="n">sx</span> <span class="o">*</span> <span class="n">sy</span> <span class="o">-</span> <span class="n">n</span> <span class="o">*</span> <span class="n">sxy</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">sx</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">n</span> <span class="o">*</span> <span class="n">sx2</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="p">(</span><span class="n">sx</span> <span class="o">*</span> <span class="n">sxy</span> <span class="o">-</span> <span class="n">sy</span> <span class="o">*</span> <span class="n">sx2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">sx</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">n</span> <span class="o">*</span> <span class="n">sx2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a: </span><span class="si">{a:.5f}</span><span class="s1">, b: </span><span class="si">{b:.5f}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>


<pre>a: 2.90060, b: -1.38144
</pre>

<p>我们来直观地看一下我们找到的模型：</p>
<div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img src="data:image/png;base64,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
"/></p>
<p>虽然我们找到的模型（绿色的直线）并不是“真理”（蓝色的直线），但是在<em>观测的范围内</em>，我们的模型跟真理非常靠近。值得注意的是，对于两条不同且不平行的直线，只要 <span class="math">\(x\)</span> 值足够大，它们的 <span class="math">\(y\)</span> 值会相差很远。所以我们在使用机器学习的时候要特别注意模型的适用范围。</p>
<p>回到优化这个问题。如果每个模型的参数我们都能通过微积分的方法给出每个参数关于观测点的公式，那么这是极好的。在残酷复杂的现实中，这种幻想是天真的。只要模型稍微复杂些，求解参数公式就变得不可能了。那么对于复杂的模型，我们有什么办法根据标准去优化它的参数呢？答案还在微积分中：<em>梯度下降法 (<a href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a>)</em> 以及<em>链式法则 (<a href="https://en.wikipedia.org/wiki/Chain_rule">chain rule</a>)</em>。</p>
<p>假设 <span class="math">\(f(x)\)</span> 是一个多元函数（<span class="math">\(x\)</span> 是一个向量）。它的梯度 <span class="math">\(\nabla f\)</span> 能指出 <span class="math">\(f\)</span> 在每个点增加最快的方向。相对地，<span class="math">\(-\nabla f\)</span> 则给出 <span class="math">\(f\)</span> 在每个点减小最快的方向。比如在 <span class="math">\(x = x_0\)</span> 这个点上，<span class="math">\(x\)</span> 要往 <span class="math">\(-\nabla f(x_0)\)</span> 这个方向走能使 <span class="math">\(f\)</span> 减小最多。梯度下降法就是根据这个想法给出的优化方法：<br>
</p>
<div class="math">$$x_0 = x_0 - \alpha \nabla f(x_0).$$</div>
<p><br>
我们从一个随机的点 <span class="math">\(x_0\)</span> 出发，重复使用上述的公式迭代 <span class="math">\(x_0\)</span> 的值来找到一个使 <span class="math">\(f\)</span> 最小的 <span class="math">\(x_0\)</span>。公式中的 <span class="math">\(\alpha\)</span> 是一个大于0的数，代表往 <span class="math">\(-\nabla f(x_0)\)</span> 方向走出的距离。其术语是<em>学习率 (learning rate)</em>。</p>
<p>在我们线性回归的例子中，我们想优化的是 <span class="math">\(L_2\)</span>。它的梯度是 <span class="math">\(\nabla L_2 = (\frac{\partial L_2}{\partial a}, \frac{\partial L_2}{\partial b})\)</span>。我们之前已经算过这两个偏导数了：<br>
</p>
<div class="math">$$\begin{align*}
    &amp;\frac{\partial L_2}{\partial a} = \frac{1}{n} \sum_{i = 1}^n (ax_i+b-y_i)x_i = \frac{1}{n}\left(\sum_{i=1}^n x_i^2\right)a + \frac{1}{n}\left(\sum_{i=1}^n x_i\right)b - \frac{1}{n}\left(\sum_{i=1}^n x_iy_i\right), \\
    &amp;\frac{\partial L_2}{\partial b} = \frac{1}{n} \sum_{i = 1}^n (ax_i+b-y_i) = \frac{1}{n}\left(\sum_{i=1}^n x_i\right)a + b - \frac{1}{n}\left(\sum_{i=1}^n y_i\right).
\end{align*}$$</div>
<p><br>
梯度下降法给出的迭代公式是<br>
</p>
<div class="math">$$\begin{align*}
    &amp; a_0 = a_0 - \alpha \frac{\partial L_2}{\partial a}(a_0, b_0), \\
    &amp; b_0 = b_0 - \alpha \frac{\partial L_2}{\partial b}(a_0, b_0).
\end{align*}$$</div>
<p><br>
我们随机化 <span class="math">\(a_0\)</span> 和 <span class="math">\(b_0\)</span>，使用 <span class="math">\(\alpha = 0.1\)</span> 迭代100次。然后我们比较一下用梯度下降法得到的 <span class="math">\(a_0\)</span> 和 <span class="math">\(b_0\)</span>，以及用公式得到的 <span class="math">\(a\)</span> 和 <span class="math">\(b\)</span>。</p>
<div class="highlight"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">a0</span><span class="p">,</span> <span class="n">b0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">ga</span> <span class="o">=</span> <span class="p">(</span><span class="n">sx2</span> <span class="o">*</span> <span class="n">a0</span> <span class="o">+</span> <span class="n">sx</span> <span class="o">*</span> <span class="n">b0</span> <span class="o">-</span> <span class="n">sxy</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
    <span class="n">gb</span> <span class="o">=</span> <span class="p">(</span><span class="n">sx</span> <span class="o">*</span> <span class="n">a0</span> <span class="o">-</span> <span class="n">sy</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span> <span class="o">+</span> <span class="n">b0</span>
    <span class="n">a0</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">ga</span>
    <span class="n">b0</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">gb</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a0: </span><span class="si">{a0:.5f}</span><span class="s1">, b0: </span><span class="si">{b0:.5f}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a: </span><span class="si">{a:.5f}</span><span class="s1">, b: </span><span class="si">{b:.5f}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>


<pre>a0: 2.83866, b0: -1.19253
a: 2.90060, b: -1.38144
</pre>

<p>我们从这个具体的例子看到梯度下降法是求解模型参数的可行性。若是选定了损失函数 <span class="math">\(L\)</span>，对于每个参数 <span class="math">\(a\)</span>，我们只需知道 <span class="math">\(L\)</span> 相对于 <span class="math">\(a\)</span> 的偏导数 <span class="math">\(\frac{\partial L}{\partial a}\)</span> 就可以使用梯度下降法了。对于一个复杂的模型，我们需要使用链式法则来求出所有参数的偏导数。链式法则是关于复合函数 (composition function) 的求导方法：<br>
</p>
<div class="math">$$\frac{\partial f(g(x))}{\partial x} = \frac{\partial f}{\partial x}(g(x)) \cdot \frac{\partial g}{\partial x}(x)$$</div>
<p><br>
用一个简略的图，一个复合函数是如下图<br>
</p>
<div class="math">$$\xrightarrow{x} g(x) \xrightarrow{u} f(x) \xrightarrow{v}$$</div>
<p><br>
以 <span class="math">\(x\)</span> 为输入，<span class="math">\(v\)</span> 为输出的函数。其中 <span class="math">\(u = g(x), v = f(u)\)</span>。那么链式法则是说<br>
</p>
<div class="math">$$\frac{\partial v}{\partial x} = \frac{\partial f}{\partial x}(u) \cdot \frac{\partial g}{\partial x}(x) $$</div>
<p>机器学习中的复杂模型可以抽象地看成有多个简单模型复合而成的。一个简单的模型可以抽象地看作一个函数 <span class="math">\(f(x; a)\)</span>。其中 <span class="math">\(x\)</span> 代表模型的输入，而分号后边的变量 <span class="math">\(a\)</span> 则代表模型的参数。我们来看一个有两个简单模型复合而成的模型：<br>
</p>
<div class="math">$$\xrightarrow{x} f(x; a) \xrightarrow{u} g(x; b) \xrightarrow{v} L(x) \xrightarrow{w}$$</div>
<p><br>
如果我们想用梯度下降法，我们必须要知道 <span class="math">\(\frac{\partial w}{\partial a}\)</span> <span class="math">\(\frac{\partial w}{\partial b}\)</span>。根据链式法则，我们得到<br>
</p>
<div class="math">$$\begin{align*}
    &amp;\frac{\partial w}{\partial b} = \frac{\partial L}{\partial x}(v) \cdot \frac{\partial g}{\partial b}(u; b), \\
    &amp;\frac{\partial w}{\partial a} = \frac{\partial L}{\partial x}(v) \cdot \frac{\partial g}{\partial x}(u; b) \cdot \frac{\partial f}{\partial a}(x; a).
\end{align*}$$</div>
<p>观察上述求偏导数的公式，我们发现在求某个模型参数的偏导数的时候我们需要后面的导数以及模型本身对参数的偏导数。比如 <span class="math">\(\frac{\partial w}{\partial b}\)</span> 需要后面的导数 <span class="math">\(\frac{\partial L}{\partial x}(v)\)</span> 以及模型本身对参数的偏导数 <span class="math">\(\frac{\partial g}{\partial b}(u; b)\)</span>；<span class="math">\(\frac{\partial w}{\partial a}\)</span> 需要后面的导数 <span class="math">\(\frac{\partial L}{\partial x}(v) \cdot \frac{\partial g}{\partial x}(u; b)\)</span> 以及模型本身对参数的偏导数 <span class="math">\(\frac{\partial f}{\partial a}(x; a)\)</span>。这样的观察让我们能简单地依次算出所有参数的偏导数。这个算法叫做反向传播 (<a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a>)。</p>
<p>总结一下，机器学习有三个最重要的模块：<strong>模型</strong>、<strong>标准</strong>以及<strong>优化</strong>。我们的接下来的算法实现会将这三个模块用三个 Python 类 (class) 表示。</p>
<h1>代码复用</h1>
<p>最后我们讲一下代码复用的事情。这个系列的博客是使用 <a href="https://jupyter.org">Jupyter Notebook</a> 写的，因此我们需要一种可以导入 Jupyter Notebook 的方法来复用之前的代码。我参考<a href="https://jupyter-notebook.readthedocs.io/en/4.x/examples/Notebook/rstversions/Importing%20Notebooks.html">官方的文档</a>整合出 <code>import_npnet.py</code> 的文件，其中的代码如下：</p>
<div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">import_npnet</span><span class="o">.</span><span class="n">py</span>
<span class="kn">import</span> <span class="nn">nbformat</span>
<span class="kn">import</span> <span class="nn">types</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">get_ipython</span>
<span class="kn">from</span> <span class="nn">IPython.core.interactiveshell</span> <span class="kn">import</span> <span class="n">InteractiveShell</span>
<span class="kn">from</span> <span class="nn">IPython.utils</span> <span class="kn">import</span> <span class="n">io</span> <span class="k">as</span> <span class="n">IPythonIO</span>


<span class="k">def</span> <span class="nf">import_npnet</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">shell</span> <span class="o">=</span> <span class="n">InteractiveShell</span><span class="o">.</span><span class="n">instance</span><span class="p">()</span>
    <span class="n">mod</span> <span class="o">=</span> <span class="n">types</span><span class="o">.</span><span class="n">ModuleType</span><span class="p">(</span><span class="s1">&#39;npnet&#39;</span><span class="p">)</span>
    <span class="n">mod</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s1">&#39;get_ipython&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_ipython</span>
    <span class="n">mod</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s1">&#39;npnet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mod</span>
    <span class="n">save_user_ns</span> <span class="o">=</span> <span class="n">shell</span><span class="o">.</span><span class="n">user_ns</span>
    <span class="n">shell</span><span class="o">.</span><span class="n">user_ns</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="vm">__dict__</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">IPythonIO</span><span class="o">.</span><span class="n">capture_output</span><span class="p">()</span> <span class="k">as</span> <span class="n">captured</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                <span class="n">nb_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;npnet</span><span class="si">{i}</span><span class="s1">.ipynb&#39;</span>
                <span class="n">nb</span> <span class="o">=</span> <span class="n">nbformat</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">nb_path</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">cell</span> <span class="ow">in</span> <span class="n">nb</span><span class="o">.</span><span class="n">cells</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">cell</span><span class="o">.</span><span class="n">cell_type</span> <span class="o">==</span> <span class="s1">&#39;code&#39;</span><span class="p">:</span>
                        <span class="n">code</span> <span class="o">=</span> <span class="n">shell</span><span class="o">.</span><span class="n">input_transformer_manager</span><span class="o">.</span><span class="n">transform_cell</span><span class="p">(</span>
                            <span class="n">cell</span><span class="o">.</span><span class="n">source</span><span class="p">)</span>

                        <span class="c1"># import the designated cells only,</span>
                        <span class="c1"># those marked with &#39;# import&#39; in the 1st line</span>
                        <span class="n">line</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">code</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
                        <span class="k">if</span> <span class="n">line</span> <span class="ow">and</span> <span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;#&#39;</span> <span class="ow">and</span> <span class="s1">&#39;import&#39;</span> <span class="ow">in</span> <span class="n">line</span><span class="p">:</span>
                            <span class="n">exec</span><span class="p">(</span><span class="n">code</span><span class="p">,</span> <span class="n">mod</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">shell</span><span class="o">.</span><span class="n">user_ns</span> <span class="o">=</span> <span class="n">save_user_ns</span>

    <span class="k">return</span> <span class="n">mod</span>
</pre></div>


<pre>Overwriting import_npnet.py
</pre>

<p>这个文件中只有一个函数 <code>import_npnet</code>，它接受一个整数 <code>n</code> 作为输入，代表要导入这个系列之前 <code>n</code> 篇笔记的代码。每一篇笔记都是一个 Jupyter Notebook ，名字格式是 <code>npnet{i}.ipynb</code>，其中 <code>{i}</code> 是笔记的编号。比如本笔记保存在 <code>npnet0.ipynb</code> 。对于一篇笔记，如果某个代码 Cell 的第一行是 Python 注释，而且包含 import 这个词，那么这个代码 Cell 将会被导入。这种设定是非常有必要的：以后我们要测试我们的算法，而机器学习的算法一般运行的时间都挺长的，我们希望 <code>import_npnet</code> 能跳过这些耗时测试代码。 这个函数会返回由这些代码生成的一个模块。一般来说，<code>n</code> 的值为当前笔记的编号。比如说当前是编号为0的笔记，我可以使用一下代码达到 <code>import</code> 的效果。</p>
<div class="highlight"><pre><span></span><span class="o">%</span><span class="n">run</span> <span class="n">import_npnet</span><span class="o">.</span><span class="n">py</span>
<span class="n">npnet</span> <span class="o">=</span> <span class="n">import_npnet</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">npnet</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">dir</span><span class="p">(</span><span class="n">npnet</span><span class="p">))</span>
</pre></div>


<pre><module 'npnet'>
['__doc__', '__loader__', '__name__', '__package__', '__spec__', 'get_ipython', 'npnet']
</pre>

<p>当然啦，因为这是第0篇笔记，所以以上命令并不会有什么实际效果。</p>

        <div class="tags">
        <a href="/tag/python">python</a>
        <a href="/tag/numpy">numpy</a>
        <a href="/tag/npnet">npnet</a>
        </div>


<div id="disqus_thread">
  <div class="btn_click_load">
    <button class="disqus_click_btn">阅读评论 「请确保 disqus.com 可以正常加载」</button>
  </div>
  <script>
    var disqus_shortname = 'wormtooth';
    var disqus_identifier = 'npnet0/';
    var disqus_title = '[npnet] 序言';
    var disqus_url = 'https://wormtooth.com/npnet0/';
    $('.btn_click_load').click(function() {
      (function() {
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || 
          document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
      $('.btn_click_load').css('display','none');
    });

    $.ajax({
      url: 'https://disqus.com/favicon.ico',
      timeout: 3000,
      type: 'GET',
      success: (function() {
        var dsq = document.createElement('script'); 
        dsq.type = 'text/javascript'; 
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || 
          document.getElementsByTagName('body')[0]).appendChild(dsq);
        $('.btn_click_load').css('display','none');
      })(),
      error: function() {
        $('.btn_click_load').css('display','block');
        }
      });
  </script>
  <script id="dsq-count-scr" src="//wormtooth.disqus.com/count.js" async></script>
</div>
    </div>
</div>
        </div></div>
        <div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar">
<div class="widget">
    <form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form">
        <input type="text" name="q" maxlength="20" placeholder="Search"/>
        <input type="hidden" name="sitesearch" value="https://wormtooth.com"/>
    </form>
</div><div class="widget">
    <div class="widget-title"><i class="fa fa-heart-o"> 年轻的心只有一面</i></div>
    <img src="/images/mobius_heart.png" class="nofancybox" />
</div><div class="widget">
    <div class="widget-title"><i class="fa fa-paper-plane-o"> 心情随笔</i></div>
    <p>含蓄的极致是闷骚，闷骚的极致是深情。</p>
    <span class="qed"><a href="/scribble">View All</a></span>
</div><div class="widget">
    <div class="widget-title">
        <i class="fa fa-folder-o"> Categories</i>
    </div>
    <ul class="category-list">
        <li class="category-list-item"><a class="category-list-link" href="/category/life/">Life</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/machine-learning/">Machine Learning</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/mathematics/">Mathematics</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/notes/">Notes</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/programming/">Programming</a></li>
    </ul>
</div><div class="widget">
    <div class="widget-title"><i class="fa fa-external-link"> Blogroll</i></div>
    <ul></ul>
    <a href="https://yongjiasong.com/" title="JOY DOMAIN" target="_blank">JOY DOMAIN</a>
</div>
<div class="widget">
    <div class="widget-title"><i class="fa fa-comment-o"> Recent Comments</i></div>
    <script type="text/javascript" src="//wormtooth.disqus.com/recent_comments_widget.js?num_items=5&hide_avatars=1&avatar_size=32&excerpt_length=20&hide_mods=1"></script>
</div>
        </div></div>
        <div class="pure-u-1 pure-u-lg-3-4">
<div id="footer">Copyright © 2020 <a href="/." rel="nofollow">叶某人的碎碎念.</a> <a rel="nofollow" target="_blank" href="https://getpelican.com/">Pelican</a> &amp; <a rel="nofollow", target="_blank", href="https://github.com/wormtooth/maupassant-pelican">maupassant</a>.</div>        </div>
    </div>
</div>
<a id="rocket" href="#top" class="show"></a>
<script type="text/javascript" src="/theme/js/totop.js" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.js" async></script>
<script type="text/javascript" src="/theme/js/fancybox.js" async></script>
<link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.css" />

<script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      },
      Macros: {
        N: "\\mathbb{N}",
        Z: "\\mathbb{Z}",
        Q: "\\mathbb{Q}",
        R: "\\mathbb{R}",
        C: "\\mathbb{C}"
      }
    },
    'HTML-CSS': {
      imageFont: null
    }
  });
</script>
<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.1.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>