<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport" />
    <meta content="yes" name="apple-mobile-web-app-capable" />
    <meta content="black-translucent" name="apple-mobile-web-app-status-bar-style" />
    <meta content="telephone=no" name="format-detection" />
    <title>
Markov Decision Process: Continuous states | 叶某人的碎碎念    </title>
    <link rel="stylesheet" type="text/css" href="/theme/css/style.css" />
    <link rel="stylesheet" type="text/css" href="/theme/css/pygment.css" />
    <link rel="stylesheet" type="text/css" href="/theme/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css" />
    <link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css" />
    <link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css" />
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
    <link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico" />
</head>

<body>
<div class="body_container">
    <div id="header">
        <div class="site-name">
            <a id="logo" href="/."> 叶某人的碎碎念 </a>
            <p class="description"> Believe in Mathematics </p>
        </div>
        <div id="nav-menu">
            <a href="/."><i class="fa fa-home"> Home</i></a>
            <a href="/movies/"><i class="fa fa-film"> Movies</i></a>
            <a href="/archives.html"><i class="fa fa-archive"> Archive</i></a>
        </div>
    </div>
    <div id="layout" class="pure-g">
        <div class="pure-u-1 pure-u-lg-3-4"><div class="content_container">
<div class="post">
    <h1 class="post-title">Markov Decision Process: Continuous states</h1>
    <div class="post-meta">Mar 06, 2018
    <span> | </span> <span>Machine Learning</span>
    </div>
    <a data-disqus-identifier="20180306-markov-decision-process-continuous-states/" href="/20180306-markov-decision-process-continuous-states/#disqus_thread" class="disqus-comment-count"></a>
    <div class="post-content">
        <p>I wrote this post for lecture 17 in Andrew Ng's lecture collections on <a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599">Machine Learning</a>. In my <a href="https://wormtooth.com/20180207-markov-decision-process/">previous post</a>, we discussed Markov Decision Process (MDP) in its simplest form, where the set of states and the set of actions are both finite. But in real world application, states and actions can be infinite and even continuous. For example, if we want to model states of a self-driving car in a 2D plane, we must at least have the position <span class="math">\((x, y)\)</span>, the direction <span class="math">\(\theta\)</span> of the car pointing to, its velocity <span class="math">\((v_x, v_y)\)</span> and the rate <span class="math">\(r\)</span> of change in <span class="math">\(\theta\)</span>. So the states of a car is at least a 6 dimensional space. For actions of a car, we can control how fast it goes in direction <span class="math">\(\theta\)</span> and we can also control <span class="math">\(r\)</span>. Thus the actions have dimension 2.</p>
<p>In this post, we consider only continuous states with finite actions. Indeed, actions space usually has much lower dimension than states space, so in case of continuous actions, we might just discretize the actions spaces to get a finite set of representatives of actions. One may argue that we can also discretize the states space. Yes, we can do it, but only when the dimension <span class="math">\(n\)</span> of state space is small enough: if we discretize each dimension into <span class="math">\(k\)</span> parts, then there would be <span class="math">\(k^n\)</span> many states. If <span class="math">\(n\)</span> is large, then <span class="math">\(k^n\)</span> is not feasible. This is so called the curse of dimensionality. Moreover, discretizing states space usually results in lack of smoothness.</p>
<!--more-->

<h2>Definition of MDP</h2>
<p>Let's recall the set up of MDP. </p>
<div class="qbar">
<p>Markov Decision Process (MDP) consists of fives components:</p>
<ol>
<li>a set of states <span class="math">\(S\)</span>;</li>
<li>a set of actions <span class="math">\(A\)</span>;</li>
<li>state transition distributions <span class="math">\(P_{sa}\)</span> for each <span class="math">\(s \in S\)</span> and <span class="math">\(a \in A\)</span>, where <span class="math">\(P_{sa}(s^\prime)\)</span> is the probability of changing from state <span class="math">\(s\)</span> to state <span class="math">\(s^\prime\)</span> when taking action <span class="math">\(a\)</span>;</li>
<li>discount factor <span class="math">\(\gamma \in [0, 1)\)</span>;</li>
<li>reward function <span class="math">\(R: S \to \R\)</span>.</li>
</ol>
</div>
<h2>Model</h2>
<p>Since we have continuously many states, we need some cares on the infinite family of transition distributions <span class="math">\(P_{sa}\)</span>. Actually, we are going to assume that we have a model/simulator so that given any state <span class="math">\(s \in S\)</span> and action <span class="math">\(a \in A\)</span>, we can get <span class="math">\(s^\prime \sim P_{sa}\)</span>. In the example of self-driving car, given state <span class="math">\(s\)</span> and action <span class="math">\(a\)</span>, we can calculate from physics the next state <span class="math">\(s^\prime\)</span>. This is a <em>deterministic</em> model. On the other hand, if we have a piece of codes that take <span class="math">\((s, a)\)</span> as an input and give <span class="math">\(P_{sa}\)</span> as an output, it will be called a <em>stochastic</em> model.</p>
<p>We can use machine learning algorithm to approximate a model, if we don't know it in advance. First of all, we can randomly take successive actions at some initial states. Let's say, we have<br>
</p>
<div class="math">$$\begin{split}
&amp; s_0^{(1)} \xrightarrow{a_0^{(1)}} s_1^{(1)} \xrightarrow{a_1^{(1)}} s_2^{(1)} \to \cdots \to s_T^{(1)} \\
&amp; s_0^{(2)} \xrightarrow{a_0^{(2)}} s_1^{(2)} \xrightarrow{a_1^{(2)}} s_2^{(2)} \to \cdots \to s_T^{(2)} \\
&amp; \vdots \\
&amp; s_0^{(m)} \xrightarrow{a_0^{(m)}} s_1^{(m)} \xrightarrow{a_1^{(m)}} s_2^{(m)} \to \cdots \to s_T^{(m)}
\end{split}$$</div>
<p>The next state <span class="math">\(s_{t+1}\)</span> is a function of current state <span class="math">\(s_t\)</span> and current action <span class="math">\(a_t\)</span>. If we think linear model is reasonable, we can set<br>
</p>
<div class="math">$$s_{t+1} = As_t + Ba_t,$$</div>
<p><br>
for some matrices <span class="math">\(A\)</span> and <span class="math">\(B\)</span>. Then we learn <span class="math">\(A\)</span> and <span class="math">\(B\)</span> from the above sample data:<br>
</p>
<div class="math">$$\mathrm{argmax}_{A, B} \sum_{i=1}^m \sum_{t=0}^{T-1} \left|s^{(i)}_{t+1}-\left(As^{(i)}_t+Ba_t^{(i)}\right)\right|^2.$$</div>
<p>Once we learn <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, we can have a deterministic model<br>
</p>
<div class="math">$$s_{t+1} = As_t + Ba_t,$$</div>
<p><br>
or a stochastic model<br>
</p>
<div class="math">$$s_{t+1} = As_t + Ba_t + \epsilon_t,$$</div>
<p><br>
for some <span class="math">\(\epsilon_t \sim \mathcal{N}(0, \epsilon)\)</span> with a fixed <span class="math">\(\epsilon\)</span>.</p>
<h2>Fitted value iteration</h2>
<p>We will first approximate the <em>optimal value function</em> <span class="math">\(V\)</span>, assuming that <span class="math">\(V\)</span> linearly depends on selected feature <span class="math">\(\phi(s)\)</span> of <span class="math">\(s\)</span>. Here <span class="math">\(\phi: S = \R^n \to \R^N\)</span> is a map from states space to features space. For example, we can take <span class="math">\(\phi(s)=s\)</span>. Therefore, we can write<br>
</p>
<div class="math">$$\begin{equation}
V(s) = \theta^T \cdot \phi(s),
\end{equation}$$</div>
<p><br>
for some parameter <span class="math">\(\theta \in \R^N\)</span>. Next, we are going to introduce an algorithm called <em>fitted value iteration</em> to learn <span class="math">\(\theta\)</span>:</p>
<div class="code">
<p>sample <span class="math">\(\{s^{(1)}, \cdots, s^{(m)}\} \subset S\)</span> randomly<br>
initialize <span class="math">\(\theta = 0\)</span><br>
repeat {<br>
  for i = 1, ..., m {<br>
    for each action a in A {<br>
      sample <span class="math">\(s_1^\prime, \dots, s_k^\prime \sim P_{s^{(i)}, a}\)</span> using model<br>
      let <span class="math">\(q(a) = \frac{1}{k} \sum_{j=1}^k\left[R(s^{(i)})+\gamma V(s_j^\prime)\right]\)</span><br>
    }<br>
    set <span class="math">\(y^{(i)} = \max_{a \in A} q(a)\)</span><br>
  }<br>
  update <span class="math">\(\theta = \mathrm{argmin}_{\theta} \frac{1}{2}\sum_{i=1}^m \left(\theta^T \cdot \phi(s^{(i)})-y^{(i)}\right)^2\)</span><br>
}</p>
</div>
<p><strong>Remarks.</strong> (1) <span class="math">\(q(a)\)</span> is an estimate of <span class="math">\(R(s^{(i)})+\gamma E_{s^\prime \sim P_{s^{(i)}, a}}[V(s^\prime)]\)</span>. So if we have a deterministic model, we can just take <span class="math">\(k\)</span> to be <span class="math">\(1\)</span>.</p>
<p>(2) <span class="math">\(y^{(i)}\)</span> is an estimate of <span class="math">\(R(s^{(i)})+\gamma \max_a E_{s^\prime \sim P_{s^{(i)}, a}}[V(s^\prime)]\)</span>.</p>
<p>(3) We update <span class="math">\(\theta\)</span> so that <span class="math">\(V(s^{(i)}) \approx y^{(i)}\)</span>.</p>
<p>(4) Once we know <span class="math">\(V\)</span> (i.e., <span class="math">\(\theta\)</span> is determined from the algorithm above), we can calculate the <em>optimal policy</em> <span class="math">\(\pi\)</span> on the fly:<br>
</p>
<div class="math">$$\pi(s) = \mathrm{argmax}_a E_{s^\prime \sim P_{sa}}[V(s^\prime)].$$</div>
<p><br>
As <span class="math">\(q(a)\)</span>, <span class="math">\(E_{s^\prime \sim P_{sa}}[V(s^\prime)]\)</span> can be computed efficiently by sampling.</p>

        <div class="tags">
        <a href="/tag/mdp">MDP</a>
        <a href="/tag/note">note</a>
        </div>


<div id="disqus_thread">
  <div class="btn_click_load">
    <button class="disqus_click_btn">阅读评论 「请确保 disqus.com 可以正常加载」</button>
  </div>
  <script>
    var disqus_shortname = 'wormtooth';
    var disqus_identifier = '20180306-markov-decision-process-continuous-states/';
    var disqus_title = 'Markov Decision Process: Continuous states';
    var disqus_url = 'https://wormtooth.com/20180306-markov-decision-process-continuous-states/';
    $('.btn_click_load').click(function() {
      (function() {
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || 
          document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
      $('.btn_click_load').css('display','none');
    });

    $.ajax({
      url: 'https://disqus.com/favicon.ico',
      timeout: 3000,
      type: 'GET',
      success: (function() {
        var dsq = document.createElement('script'); 
        dsq.type = 'text/javascript'; 
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || 
          document.getElementsByTagName('body')[0]).appendChild(dsq);
        $('.btn_click_load').css('display','none');
      })(),
      error: function() {
        $('.btn_click_load').css('display','block');
        }
      });
  </script>
  <script id="dsq-count-scr" src="//wormtooth.disqus.com/count.js" async></script>
</div>
    </div>
</div>
        </div></div>
        <div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar">
<div class="widget">
    <form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form">
        <input type="text" name="q" maxlength="20" placeholder="Search"/>
        <input type="hidden" name="sitesearch" value="https://wormtooth.com"/>
    </form>
</div><div class="widget">
    <div class="widget-title"><i class="fa fa-heart-o"> 年轻的心只有一面</i></div>
    <img src="/images/mobius_heart.png" class="nofancybox" />
</div><div class="widget">
    <div class="widget-title"><i class="fa fa-paper-plane-o"> 心情随笔</i></div>
    <p>含蓄的极致是闷骚，闷骚的极致是深情。</p>
    <span class="qed"><a href="/scribble">View All</a></span>
</div><div class="widget">
    <div class="widget-title">
        <i class="fa fa-folder-o"> Categories</i>
    </div>
    <ul class="category-list">
        <li class="category-list-item"><a class="category-list-link" href="/category/life/">Life</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/machine-learning/">Machine Learning</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/mathematics/">Mathematics</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/notes/">Notes</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/programming/">Programming</a></li>
    </ul>
</div><div class="widget">
    <div class="widget-title"><i class="fa fa-external-link"> Blogroll</i></div>
    <ul></ul>
    <a href="https://yongjiasong.com/" title="JOY DOMAIN" target="_blank">JOY DOMAIN</a>
</div>
<div class="widget">
    <div class="widget-title"><i class="fa fa-comment-o"> Recent Comments</i></div>
    <script type="text/javascript" src="//wormtooth.disqus.com/recent_comments_widget.js?num_items=5&hide_avatars=1&avatar_size=32&excerpt_length=20&hide_mods=1"></script>
</div>
        </div></div>
        <div class="pure-u-1 pure-u-lg-3-4">
<div id="footer">Copyright © 2020 <a href="/." rel="nofollow">叶某人的碎碎念.</a> <a rel="nofollow" target="_blank" href="https://getpelican.com/">Pelican</a> &amp; <a rel="nofollow", target="_blank", href="https://github.com/wormtooth/maupassant-pelican">maupassant</a>.</div>        </div>
    </div>
</div>
<a id="rocket" href="#top" class="show"></a>
<script type="text/javascript" src="/theme/js/totop.js" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.js" async></script>
<script type="text/javascript" src="/theme/js/fancybox.js" async></script>
<link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.css" />

<script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      },
      Macros: {
        N: "\\mathbb{N}",
        Z: "\\mathbb{Z}",
        Q: "\\mathbb{Q}",
        R: "\\mathbb{R}",
        C: "\\mathbb{C}"
      }
    },
    'HTML-CSS': {
      imageFont: null
    }
  });
</script>
<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.1.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>